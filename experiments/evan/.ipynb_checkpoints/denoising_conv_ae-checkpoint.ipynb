{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import theano\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer, Conv2DLayer, Pool2DLayer, DropoutLayer, \\\n",
    "Deconv2DLayer, DenseLayer, Upscale2DLayer, ReshapeLayer, \\\n",
    "get_output, get_all_params, get_all_layers,  count_params\n",
    "from lasagne.nonlinearities import rectify as relu\n",
    "from lasagne.nonlinearities import linear\n",
    "from lasagne.objectives import squared_error\n",
    "from lasagne.updates import nesterov_momentum\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import copy\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.insert(0,'..')\n",
    "    from common import _day_iterator\n",
    "else:\n",
    "    from ..common import _day_iterator\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "#import util.preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nolearn.lasagne import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_network(nkwargs):\n",
    "    \n",
    "    opt_kwargs = {k:nkwargs[k] for k in ['learning_rate','momentum']}\n",
    "\n",
    "    \n",
    "\n",
    "    network, hid_layer = build_denoising_convae(input_var, nkwargs)\n",
    "    \n",
    "    #get outputs\n",
    "    prediction = get_output(network, deterministic=False)\n",
    "    hid_layer_output = get_output(hid_layer, deterministic=True)\n",
    "    \n",
    "    #make losses\n",
    "    loss = squared_error(prediction, target_var).mean()\n",
    "    test_prediction = get_output(network, deterministic=True)\n",
    "    test_loss = squared_error(test_prediction,target_var).mean()\n",
    "    test_acc = test_loss \n",
    "    \n",
    "    #set up updates\n",
    "    params = get_all_params(network, trainable=True)\n",
    "    updates = nesterov_momentum(loss, params, **opt_kwargs)\n",
    "\n",
    "    \n",
    "    #make fns\n",
    "    train_fn = function([input_var, target_var], loss, updates=updates)\n",
    "    val_fn = function([input_var, target_var], [test_loss, test_acc])\n",
    "    pred_fn = function([input_var], test_prediction)\n",
    "    hlayer_fn = function([input_var], hid_layer_output )\n",
    "\n",
    "    return train_fn, val_fn, pred_fn, hlayer_fn, network\n",
    "\n",
    "def build_denoising_convae(input_var, nkwargs):\n",
    "    \n",
    "    corrupted_input = corrupt(input_var, nkwargs)\n",
    "    \n",
    "    hid_layer = build_encoder(corrupted_input, nkwargs)\n",
    "    \n",
    "\n",
    "    network = build_decoder(hid_layer, nkwargs)\n",
    "\n",
    "    print_layers(network)\n",
    "    \n",
    "    return network, hid_layer\n",
    "\n",
    "def build_encoder(input_var, nkwargs):\n",
    "    \n",
    "    conv_kwargs = {k: nkwargs[k] for k in ['num_filters', 'W', 'nonlinearity']}\n",
    "    dense_kwargs = {k: nkwargs[k] for k in ['num_units','W', 'nonlinearity']}\n",
    "    \n",
    "    net = InputLayer(shape=nkwargs['input_shape'], input_var=input_var)\n",
    "    net = Conv2DLayer(net, filter_size=(2,2), pad=(2,0), stride=(1,2), **conv_kwargs)\n",
    "    net = Conv2DLayer(net, filter_size=(2,2),pad=(1,0),stride=2, **conv_kwargs)\n",
    "    net = DropoutLayer(net, p=nkwargs['p'])\n",
    "    net = DenseLayer(net, **dense_kwargs)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_decoder(hid_layer, nkwargs):\n",
    "    \n",
    "    # the last shape before the fully connected layers\n",
    "    last_conv_shape = get_last_conv_shape(hid_layer)\n",
    "    \n",
    "    #set kwargs\n",
    "    dc_kwargs = {k: nkwargs[k] for k in ['num_filters', 'W', 'nonlinearity']}\n",
    "    edc_kwargs = dict(num_filters=nkwargs['input_shape'][1],W=nkwargs['W'], nonlinearity=linear)\n",
    "    fc_kwargs = {k: nkwargs[k] for k in ['W', 'nonlinearity']}\n",
    "    fc_kwargs.update({'num_units': np.prod(last_conv_shape[1:]) })\n",
    "\n",
    "    #make layers\n",
    "    net = DropoutLayer(hid_layer, p=nkwargs['p'])\n",
    "    net = DenseLayer(net, **fc_kwargs)\n",
    "    d1, d2, d3 = last_conv_shape[1:]\n",
    "    net = ReshapeLayer(net, shape= ([0], d1,d2,d3))\n",
    "    net = Deconv2DLayer(net, filter_size=(3,2), crop=(1,0), stride=(2,2), **dc_kwargs)\n",
    "    net = Deconv2DLayer(net,filter_size=(2,2), crop=(2,0), stride=(1,2),**edc_kwargs)\n",
    "    \n",
    "    return net\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def corrupt(input_var, nkwargs):\n",
    "    rng = np.random.RandomState(498)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "    \n",
    "    if 'corruption' not in nkwargs:\n",
    "        corrupted_input = input_var\n",
    "    elif nkwargs['corruption'] == 'binomial':\n",
    "        corruped_input = theano_rng.binomial(size=input_var.shape, n=1,p=1 - corruption_p) * input_var\n",
    "    elif nkwargs['corruption'] in ['gaussian', 'normal']:\n",
    "        corrupted_input = theano_rng.normal(size=input_var.shape, avg=0.0, std=1.0) * input_var\n",
    "    else:\n",
    "        corrupted_input = input_var\n",
    "                    \n",
    "    return corrupted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_last_conv_shape(network):\n",
    "    lay = copy.deepcopy(network)\n",
    "    while type(lay) != lasagne.layers.conv.Conv2DLayer:\n",
    "        lay = lay.input_layer\n",
    "    last_conv_shape = lay.output_shape\n",
    "    return last_conv_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_layers(network):\n",
    "    for layer in get_all_layers(network):\n",
    "        print str(type(layer)).split(\".\")[-1][:-2] +': ' + str(layer.output_shape)\n",
    "    print count_params(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 8, 16, 128, 128)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e5f492b26107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_day_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in _day_iterator():\n",
    "    print x.shape\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    if batchsize > inputs.shape[0]:\n",
    "        batchsize=inputs.shape[0]\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputLayer: (None, 2, 8, 24)\n",
      "Conv2DLayer: (None, 128, 11, 12)\n",
      "Conv2DLayer: (None, 128, 6, 6)\n",
      "DropoutLayer: (None, 128, 6, 6)\n",
      "DenseLayer: (None, 1024)\n",
      "DropoutLayer: (None, 1024)\n",
      "DenseLayer: (None, 4608)\n",
      "ReshapeLayer: (None, 128, 6, 6)\n",
      "TransposedConv2DLayer: (None, 128, 11, 12)\n",
      "TransposedConv2DLayer: (None, 2, 8, 24)\n",
      "9609090\n",
      "# Neural Network with 9609090 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #    name  size\n",
      "---  ------  ---------\n",
      "  0          2x8x24\n",
      "  1          128x11x12\n",
      "  2          128x6x6\n",
      "  3          128x6x6\n",
      "  4          1024\n",
      "  5          1024\n",
      "  6          4608\n",
      "  7          128x6x6\n",
      "  8          128x11x12\n",
      "  9          2x8x24\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val  dur\n",
      "-------  ----------  ----------  ---------  -----\n",
      "      1     \u001b[36m0.35850\u001b[0m     \u001b[32m0.30278\u001b[0m    1.18402  0.45s\n",
      "      2     \u001b[36m0.29981\u001b[0m     \u001b[32m0.23944\u001b[0m    1.25212  0.44s\n",
      "      3     \u001b[36m0.23645\u001b[0m     \u001b[32m0.18319\u001b[0m    1.29071  0.44s\n",
      "      4     \u001b[36m0.18029\u001b[0m     \u001b[32m0.14093\u001b[0m    1.27930  0.45s\n",
      "      5     \u001b[36m0.13811\u001b[0m     \u001b[32m0.11512\u001b[0m    1.19972  0.44s\n",
      "      6     \u001b[36m0.11237\u001b[0m     \u001b[32m0.10456\u001b[0m    1.07470  0.44s\n",
      "      7     \u001b[36m0.10182\u001b[0m     0.10496    0.97004  0.45s\n",
      "      8     0.10216     0.11060    0.92369  0.45s\n",
      "      9     0.10769     0.11625    0.92642  0.44s\n",
      "     10     0.11324     0.11870    0.95399  0.44s\n",
      "     11     0.11556     0.11703    0.98746  0.44s\n",
      "     12     0.11379     0.11214    1.01476  0.44s\n",
      "     13     0.10884     0.10575    1.02924  0.44s\n",
      "     14     0.10245     \u001b[32m0.09959\u001b[0m    1.02876  0.44s\n",
      "     15     \u001b[36m0.09631\u001b[0m     \u001b[32m0.09479\u001b[0m    1.01599  0.45s\n",
      "     16     \u001b[36m0.09153\u001b[0m     \u001b[32m0.09177\u001b[0m    0.99739  0.45s\n",
      "     17     \u001b[36m0.08854\u001b[0m     \u001b[32m0.09039\u001b[0m    0.97960  0.45s\n",
      "     18     \u001b[36m0.08719\u001b[0m     \u001b[32m0.09017\u001b[0m    0.96696  0.44s\n",
      "     19     \u001b[36m0.08701\u001b[0m     0.09058    0.96052  0.44s\n",
      "     20     0.08743     0.09114    0.95927  0.45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7ff135f74990>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x7ff135f74890>,\n",
       "     check_input=True, custom_scores=None,\n",
       "     layers=[<lasagne.layers.input.InputLayer object at 0x7ff11407ac90>, <lasagne.layers.conv.Conv2DLayer object at 0x7ff1211c3690>, <lasagne.layers.conv.Conv2DLayer object at 0x7ff1211c38d0>, <lasagne.layers.noise.DropoutLayer object at 0x7ff1211c3790>, <lasagne.layers.dense.DenseLayer object at 0x7ff12...yer object at 0x7ff12114be10>, <lasagne.layers.conv.TransposedConv2DLayer object at 0x7ff12114bf50>],\n",
       "     loss=None, max_epochs=5, more_params={},\n",
       "     objective=<function objective at 0x7ff135f78f50>,\n",
       "     objective_loss_function=<function squared_error at 0x7ff136f98668>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x7ff12243b908>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7ff12243ba28>],\n",
       "     regression=True, scores_train=[], scores_valid=[],\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x7ff135f749d0>,\n",
       "     update=<function nesterov_momentum at 0x7ff136f98ed8>,\n",
       "     update_learning_rate=0.01, update_momentum=0.9,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(float64, 4D))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dnkwargs = dict(         learning_rate = 0.01,\n",
    "                              input_shape=(None,2,8,24),\n",
    "                              momentum = 0.9,\n",
    "                              num_filters=128,\n",
    "                              num_units=1024,\n",
    "                              nonlinearity=relu,\n",
    "                              W=lasagne.init.HeNormal(),\n",
    "                              p=0.,\n",
    "                              corruption_p = 0.3,\n",
    "                              load=False, \n",
    "                              load_path=None,)\n",
    "    \n",
    "    train_fn, val_fn, pred_fn, hlayer_fn, network = build_network(dnkwargs)\n",
    "    \n",
    "    \n",
    "\n",
    "input_var = T.tensor4('input_var')\n",
    "target_var = T.tensor4('target_var')\n",
    "\n",
    "ae = NeuralNet(\n",
    "       layers=get_all_layers(network), \n",
    "       max_epochs=5, \n",
    "       update=nesterov_momentum,\n",
    "       update_learning_rate=0.01, \n",
    "       update_momentum=0.9,\n",
    "       objective_loss_function=squared_error,\n",
    "       regression=True, \n",
    "       verbose=1, \n",
    "       y_tensor_type=target_var.type)\n",
    "        \n",
    "\n",
    "X = np.random.random((100,2,8,24))\n",
    "hinit = hlayer_fn(X)\n",
    "ae.fit(X,X, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hfinal = hlayer_fn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = TSNE().fit_transform(hfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff126705850>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1165b9310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ts[:,0], ts[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itertools.product"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
