{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.objectives import *\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.updates import *\n",
    "from lasagne.utils import *\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import time\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.insert(0,'..')\n",
    "    from common import create_run_dir, plot_learn_curve\n",
    "else:\n",
    "    from ..common import create_run_dir, plot_learn_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    sys.argv=sys.argv[:1]\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-n', '--num_ims', default=2000, type=int,\n",
    "    help='number of total images')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "ims = mnist['data']\n",
    "\n",
    "ims.shape\n",
    "\n",
    "ims = ims.reshape(ims.shape[0],1, 28,28).astype('float64')\n",
    "\n",
    "lbls = mnist['target'].astype('int32')\n",
    "ims= ims[:args.num_ims]\n",
    "lbls = lbls[:args.num_ims]\n",
    "ims -= np.mean(ims)\n",
    "ims /= np.var(ims)\n",
    "\n",
    "num_ims = ims.shape[0]\n",
    "inds = np.arange(num_ims)\n",
    "np.random.RandomState(11).shuffle(inds)\n",
    "ims= ims[inds]\n",
    "lbls =lbls[inds]\n",
    "\n",
    "im_tr, lbl_tr, im_val, lbl_val = ims[:int(0.8*num_ims)], lbls[:int(0.8*num_ims)], \\\n",
    "                                 ims[int(0.8*num_ims):], lbls[int(0.8*num_ims):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    if batchsize > inputs.shape[0]:\n",
    "        batchsize=inputs.shape[0]\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net(net_cfg, args):\n",
    "    l_out = net_cfg(args)\n",
    "    X = T.tensor4('X')\n",
    "    Y= T.ivector('Y')\n",
    "    net_out = get_output(l_out, X)\n",
    "    loss = categorical_crossentropy(net_out, Y).mean()\n",
    "    net_out_det = get_output(l_out, X, deterministic=True)\n",
    "    acc = lasagne.objectives.categorical_accuracy(net_out_det,Y).mean()\n",
    "    params = get_all_params(l_out, trainable=True)\n",
    "    lr = theano.shared(floatX(args[\"learning_rate\"]))\n",
    "    if \"rmsprop\" in args:\n",
    "        updates = rmsprop(loss, params, learning_rate=lr)\n",
    "    else:\n",
    "        updates = nesterov_momentum(loss, params, learning_rate=lr, momentum=0.9)\n",
    "    #updates = adadelta(loss, params, learning_rate=lr)\n",
    "    #updates = rmsprop(loss, params, learning_rate=lr)\n",
    "    train_fn = theano.function([X, Y], loss, updates=updates)\n",
    "    loss_fn = theano.function([X, Y], loss)\n",
    "    val_fn = theano.function([X,Y], [loss,acc])\n",
    "    out_fn = theano.function([X], net_out_det)\n",
    "    return {\n",
    "        \"train_fn\": train_fn,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"out_fn\": out_fn,\n",
    "        \"val_fn\": val_fn,\n",
    "        \"lr\": lr,\n",
    "        \"l_out\": l_out\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net_ae(net_cfg, args):\n",
    "    l_out, hid_layer = net_cfg(args)\n",
    " \n",
    "    X = T.tensor4('X')\n",
    "    Y = T.ivector('Y')\n",
    "    net_out = get_output(l_out, X)\n",
    "    hid_out = get_output(hid_layer, X)\n",
    "\n",
    "    \n",
    "    clsf_loss = get_classifier_loss(hid_layer,X,Y,args)\n",
    "    rec_loss = squared_error(net_out, X).mean()\n",
    "    if args['with_classif_loss']:\n",
    "        loss = args['lrec'] * rec_loss + clsf_loss\n",
    "        inputs = [X,Y]\n",
    "    else:\n",
    "        loss = rec_loss\n",
    "        inputs=[X]\n",
    "    params = get_all_params(l_out, trainable=True)\n",
    "    lr = theano.shared(floatX(args[\"learning_rate\"]))\n",
    "    updates = nesterov_momentum(loss, params, learning_rate=lr, momentum=0.9)\n",
    "    train_fn = theano.function(inputs, loss, updates=updates)\n",
    "    loss_fn = theano.function(inputs, loss)\n",
    "    out_fn = theano.function([X], net_out)\n",
    "    hid_fn = theano.function([X],hid_out)\n",
    "    return {\n",
    "        \"train_fn\": train_fn,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"out_fn\": out_fn,\n",
    "        \"lr\": lr,\n",
    "        \"l_out\": l_out,\n",
    "        \"h_fn\": hid_fn,\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dense_conv_encoder(args):\n",
    "    conv_kwargs = dict(filter_size=3, pad=1, nonlinearity=args['nonlinearity'])\n",
    "    inp = InputLayer(args[\"input_shape\"])\n",
    "    conc = Conv2DLayer(inp, num_filters=args['k0'], **conv_kwargs)\n",
    "    conv_kwargs.update({'num_filters': args['k'], 'nonlinearity': None})\n",
    "    for j in range(args['B']):\n",
    "        conc = make_dense_block(conc, args, conv_kwargs=conv_kwargs)\n",
    "        if j < args['B'] - 1:\n",
    "            conc = make_trans_layer(conc, args)\n",
    "    return conc\n",
    "\n",
    "            \n",
    "def make_dense_conv_classifier(args):  \n",
    "    conc = make_dense_conv_encoder(args)\n",
    "    conc = Pool2DLayer(conc, pool_size=2, stride=2,mode='average_exc_pad')\n",
    "    sm = DenseLayer(conc, num_units=args['num_classes'], nonlinearity=softmax)\n",
    "    for layer in get_all_layers(sm):\n",
    "        print  layer, layer.output_shape\n",
    "    print count_params(layer)\n",
    "    print sm.output_shape\n",
    "    return sm\n",
    "\n",
    "    \n",
    "\n",
    "def make_dense_block(inp, args, conv_kwargs={}):\n",
    "        conc = inp\n",
    "        block_layers = [conc]\n",
    "        for i in range(args['L']):\n",
    "            bn = BatchNormLayer(conc)\n",
    "            bn_relu = NonlinearityLayer(bn ,nonlinearity=args['nonlinearity'])\n",
    "            bn_relu_conv = Conv2DLayer(bn_relu, **conv_kwargs)\n",
    "            block_layers.append(bn_relu_conv)\n",
    "            conc = ConcatLayer(block_layers, axis=1)\n",
    "        return conc\n",
    "\n",
    "def make_trans_layer(inp,args):\n",
    "    conc = inp\n",
    "    conv = Conv2DLayer(conc, num_filters=conc.output_shape[1], filter_size=1)\n",
    "    conc = Pool2DLayer(conv, pool_size=2,stride=2, mode='average_exc_pad')\n",
    "    return conc\n",
    "\n",
    "def make_inverse_trans_layer(inp, layer):\n",
    "    conc = inp\n",
    "    #because trans layers are 2 layerrs log\n",
    "    for lay in get_all_layers(layer)[::-1][:2]:\n",
    "        #print \"*******************\\n\\n\",lay, \"\\n\\n********************\\n\\n\"\n",
    "        conc = make_inverse(conc, lay)\n",
    "    \n",
    "    #return whole network and next layer we are going to invert\n",
    "    return conc, lay.input_layer\n",
    "\n",
    "def make_inverse_dense_block(inp, layer, args):\n",
    "    conc = inp\n",
    "    block_layers = [conc]\n",
    "    #3 layers per comp unit and args['L'] units per block\n",
    "    for lay in get_all_layers(layer)[::-1][:4*args['L']]:\n",
    "        if isinstance(lay, Conv2DLayer):\n",
    "            conc = BatchNormLayer(conc)\n",
    "            conc = make_inverse(conc, lay, filters=args['k'])\n",
    "            conc = NonlinearityLayer(conc, nonlinearity=args['nonlinearity'])\n",
    "            block_layers.append(conc)\n",
    "            if args['concat_inver']:\n",
    "                conc = ConcatLayer(block_layers,axis=1)\n",
    "            \n",
    "    return conc, lay.input_layer\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "def make_inverse(l_in, layer, filters=None):\n",
    "    \n",
    "    if isinstance(layer, Conv2DLayer):\n",
    "        if filters is None:\n",
    "            filters = layer.input_shape[1]\n",
    "        return Deconv2DLayer(l_in, filters, layer.filter_size, stride=layer.stride, crop=layer.pad,\n",
    "                             nonlinearity=layer.nonlinearity)\n",
    "    elif isinstance(layer, Pool2DLayer) or isinstance(layer, DenseLayer):\n",
    "        return InverseLayer(l_in, layer)\n",
    "    else:\n",
    "        return l_in\n",
    "\n",
    "def make_dense_conv_autoencoder(args):\n",
    "    conc = make_dense_conv_encoder(args)\n",
    "    conc = make_trans_layer(conc, args)\n",
    "    last_conv_shape = tuple([k if k is not None else [i] for i,k in enumerate(get_output_shape(conc,args['input_shape']))] )\n",
    "    hid_lay = DenseLayer(conc, num_units=args['num_fc_units'])\n",
    "    rec = DenseLayer(hid_lay,num_units=np.prod(last_conv_shape[1:]))\n",
    "    conc = ReshapeLayer(rec, shape=last_conv_shape)\n",
    "    \n",
    "    \n",
    "    for layer in get_all_layers(conc)[::-1]:\n",
    "        if not isinstance(layer, DenseLayer) and not isinstance(layer, ReshapeLayer):\n",
    "            break\n",
    "        \n",
    "    for i in range(args['B']):\n",
    "        conc, layer = make_inverse_trans_layer(conc, layer)\n",
    "        #print \"lol: \", layer\n",
    "        conc, layer = make_inverse_dense_block(conc, layer, args)\n",
    "        \n",
    "\n",
    "    for lay in get_all_layers(layer)[::-1]:\n",
    "        if isinstance(lay, InputLayer):\n",
    "            break\n",
    "        conc = make_inverse(conc, lay)\n",
    "    for layer_ in get_all_layers(conc):\n",
    "            print  layer_, layer_.output_shape\n",
    "    print count_params(layer_)\n",
    "    \n",
    "    \n",
    "    return conc\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = {\"B\":2, \"L\": 2, 'k':3, 'k0':16, \"num_classes\":10, \"num_fc_units\":100,'concat_inver':True, \"input_shape\": (None,1,28,28), \"learning_rate\": 0.01, \"sigma\":0.1, \"nonlinearity\":elu, \"f\":128, \"tied\":False }\n",
    "#net_cfg = get_net(make_dense_conv_classifier, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x2b352944aa50> (None, 1, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b352944acd0> (None, 16, 28, 28)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b3529817050> (None, 16, 28, 28)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529817490> (None, 16, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b35292ba950> (None, 3, 28, 28)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b3529817690> (None, 19, 28, 28)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b3529817810> (None, 19, 28, 28)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529817c50> (None, 19, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b3529817d90> (None, 3, 28, 28)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b3529817e10> (None, 22, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b352944afd0> (None, 22, 28, 28)\n",
      "<lasagne.layers.pool.Pool2DLayer object at 0x2b352946e050> (None, 22, 14, 14)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b352946e210> (None, 22, 14, 14)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b352946e650> (None, 22, 14, 14)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b352946e790> (None, 3, 14, 14)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b352946e8d0> (None, 25, 14, 14)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b352946ea50> (None, 25, 14, 14)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b352946ee90> (None, 25, 14, 14)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b352946efd0> (None, 3, 14, 14)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b35296cb150> (None, 28, 14, 14)\n",
      "<lasagne.layers.pool.Pool2DLayer object at 0x2b352944ae10> (None, 28, 7, 7)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x2b352946e1d0> (None, 10)\n",
      "16950\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "cnet = make_dense_conv_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lasagne.layers.input.InputLayer object at 0x2b3527fba710> (None, 1, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b35294a1b90> (None, 16, 28, 28)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b3527db5c90> (None, 16, 28, 28)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529285410> (None, 16, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b35292ba6d0> (None, 3, 28, 28)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b3529285650> (None, 19, 28, 28)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b35292857d0> (None, 19, 28, 28)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529285c10> (None, 19, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b3529285d50> (None, 3, 28, 28)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b3529285e90> (None, 22, 28, 28)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b35291db5d0> (None, 22, 28, 28)\n",
      "<lasagne.layers.pool.Pool2DLayer object at 0x2b3529573150> (None, 22, 14, 14)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b3529573310> (None, 22, 14, 14)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529573750> (None, 22, 14, 14)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b3529573890> (None, 3, 14, 14)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b35295739d0> (None, 25, 14, 14)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b3529573b50> (None, 25, 14, 14)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529573f90> (None, 25, 14, 14)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b35294b5110> (None, 3, 14, 14)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b35294b5250> (None, 28, 14, 14)\n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x2b35294a1d10> (None, 28, 14, 14)\n",
      "<lasagne.layers.pool.Pool2DLayer object at 0x2b35294b5490> (None, 28, 7, 7)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x2b35294b5610> (None, 100)\n",
      "<lasagne.layers.dense.DenseLayer object at 0x2b35294b5750> (None, 1372)\n",
      "<lasagne.layers.shape.ReshapeLayer object at 0x2b35294b59d0> (None, 28, 7, 7)\n",
      "<lasagne.layers.special.InverseLayer object at 0x2b35294b5bd0> (None, 28, 14, 14)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b35294b5c10> (None, 28, 14, 14)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b35294b5d50> (None, 28, 14, 14)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b35294b6310> (None, 3, 14, 14)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b35294b6550> (None, 3, 14, 14)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b35294b66d0> (None, 31, 14, 14)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b35294b6710> (None, 31, 14, 14)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b35294b6b50> (None, 3, 14, 14)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b35294b6d90> (None, 3, 14, 14)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b35294b6f10> (None, 34, 14, 14)\n",
      "<lasagne.layers.special.InverseLayer object at 0x2b35294b6f50> (None, 22, 28, 28)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b35294b6f90> (None, 22, 28, 28)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b352948e110> (None, 22, 28, 28)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b352948e690> (None, 3, 28, 28)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b352948e8d0> (None, 3, 28, 28)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b352948ea50> (None, 25, 28, 28)\n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x2b352948ea90> (None, 25, 28, 28)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b352948eed0> (None, 3, 28, 28)\n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x2b3529477150> (None, 3, 28, 28)\n",
      "<lasagne.layers.merge.ConcatLayer object at 0x2b35294772d0> (None, 28, 28, 28)\n",
      "<lasagne.layers.conv.TransposedConv2DLayer object at 0x2b35294b5b90> (None, 1, 28, 28)\n",
      "284773\n"
     ]
    }
   ],
   "source": [
    "net = make_dense_conv_autoencoder(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nolearn import lasagne as ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'visualize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-0c1e1f8aab34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'visualize'"
     ]
    }
   ],
   "source": [
    "ls.visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 5000\n",
    "batch_size = 128\n",
    "import logging\n",
    "run_dir = create_run_dir()\n",
    "try:\n",
    "    print logger\n",
    "except:\n",
    "    logger = logging.getLogger('log_train')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    fh = logging.FileHandler('%s/training.log'%(run_dir))\n",
    "    fh.setLevel(logging.INFO)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "logger.info(\"train size = %i, val size = %i\"%(im_tr.shape[0], im_val.shape[0])) \n",
    "tr_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time() \n",
    "    tr_loss = 0\n",
    "    for iteration, (x, y) in enumerate(iterate_minibatches(im_tr,lbl_tr,batchsize=batch_size)):  \n",
    "        loss = net_cfg['train_fn'](x,y)\n",
    "        print loss\n",
    "        tr_loss += loss\n",
    "    \n",
    "    train_end = time.time()\n",
    "    tr_avgloss = tr_loss / (iteration + 1)\n",
    "    \n",
    "    \n",
    "    logger.info(\"train time : %5.2f seconds\" % (train_end - start))\n",
    "    logger.info(\" epoch %i of %i train loss is %f\" % (epoch, num_epochs, tr_avgloss))\n",
    "    tr_losses.append(tr_avgloss)\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_acc =0 \n",
    "    for iteration, (xval, yval) in enumerate(iterate_minibatches(im_val,lbl_val,batchsize=batch_size)):\n",
    "        loss,acc = net_cfg['val_fn'](xval, yval)\n",
    "        val_acc += acc\n",
    "        val_loss += loss\n",
    "    \n",
    "    val_avgacc = val_acc / (iteration + 1) \n",
    "    val_avgloss = val_loss / (iteration + 1)   \n",
    "    logger.info(\"val time : %5.2f seconds\" % (time.time() - train_end))\n",
    "\n",
    "    logger.info(\" epoch %i of %i val loss is %f\" % (epoch, num_epochs, val_avgloss))\n",
    "    logger.info(\" epoch %i of %i val acc is %f percent\" % (epoch, num_epochs, 100*val_avgacc))\n",
    "    val_losses.append(val_avgloss)\n",
    "    \n",
    "    plot_learn_curve(tr_losses, val_losses, save_dir=run_dir)\n",
    "#     if epoch % 5 == 0:\n",
    "#         plot_filters(net_cfg['l_out'], save_dir=run_dir)\n",
    "#         for iteration, (x,y) in enumerate(data_iterator(batch_size=batch_size, step_size=128, days=1, month1='01', day1='01')):\n",
    "#             plot_recs(iteration,x,net_cfg=net_cfg, save_dir=run_dir)\n",
    "#             plot_clusters(iteration,x,y,net_cfg=net_cfg, save_dir=run_dir)\n",
    "#             plot_feature_maps(iteration,x,net_cfg['l_out'], save_dir=run_dir)\n",
    "#             break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from viz import draw_to_file\n",
    "draw_to_file(get_all_layers(cnet), \"./dense_net_classifier.eps\")\n",
    "draw_to_file(get_all_layers(net), \"./dense_net_autoencoder.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/cori/software/python/2.7-anaconda/envs/deeplearning/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "matplotlib.use('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
